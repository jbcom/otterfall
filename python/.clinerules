

<!-- Source: .ruler/AGENTS.md -->

# Python Backend Development Standards

## Project Structure

```
python/
├── mesh_toolkit/          # Meshy API client library
│   └── src/mesh_toolkit/
│       ├── api/           # HTTP client
│       ├── services/      # Business logic
│       ├── persistence/   # Database & file storage
│       └── webhooks/      # Webhook handlers
├── crew_agents/           # CrewAI orchestration
│   └── src/crew_agents/
│       └── adapters/      # MCP tool adapters
└── tests/
    ├── unit/              # Fast, mocked tests
    └── integration/       # Real API calls (VCR)
```

## Testing Standards

### VCR for Expensive APIs
```python
import pytest

@pytest.mark.vcr()
def test_meshy_text3d_creates_otter():
    """VCR records on first run, replays after"""
    client = MeshyClient(api_key="test")
    task_id = client.create_text3d(prompt="otter")
    assert task_id.startswith("018")
```

See [testing_conventions.md](./testing_conventions.md) for details.

## Type Hints Required

```python
# ✅ Good
def process_webhook(
    payload: WebhookPayload,
    repository: AssetRepository
) -> WebhookResult:
    ...

# ❌ Bad
def process_webhook(payload, repository):
    ...
```

## Error Handling

### Use Result Types
```python
from typing import TypedDict

class Success(TypedDict):
    ok: Literal[True]
    value: T

class Failure(TypedDict):
    ok: Literal[False]
    error: Exception

Result = Success | Failure
```

## CrewAI Standards

See [crew_agents/.ruler/workflow_configuration.md](../crew_agents/.ruler/workflow_configuration.md) for agent hierarchy and MCP tool access patterns.



<!-- Source: .ruler/testing_conventions.md -->

# Python Testing Conventions

## Test Organization

```
tests/
├── unit/              # Fast, isolated tests with mocks
├── integration/       # Real API calls with VCR cassettes
└── conftest.py        # Shared fixtures
```

## VCR Recording Strategy

- Use `pytest-vcr` for expensive API calls (Meshy)
- Record once, replay for free
- Cassettes stored in `tests/integration/cassettes/`
- Download artifacts to `tests/integration/fixtures/`

## Test Naming

```python
# Good
def test_text3d_service_creates_task_with_valid_spec():
    pass

# Bad
def test_stuff():
    pass
```

## Assertion Style

Use descriptive assertions with context:

```python
assert result.status == TaskStatus.SUCCEEDED, \
    f"Expected SUCCEEDED but got {result.status}"
```
